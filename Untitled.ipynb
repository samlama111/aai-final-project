{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece21661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import imghdr\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, SpatialDropout2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d64a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'Detect_solar_dust'\n",
    "\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "# check all images are openable\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Failed to load image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Add random seed of training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore params\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f90751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "  features, labels = batch\n",
    "  class_1 = labels == 1\n",
    "  class_1 = tf.cast(class_1, tf.int32)\n",
    "\n",
    "  class_0 = labels == 0\n",
    "  class_0 = tf.cast(class_0, tf.int32)\n",
    "\n",
    "  counts['class_0'] += tf.reduce_sum(class_0)\n",
    "  counts['class_1'] += tf.reduce_sum(class_1)\n",
    "\n",
    "  return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8092dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data.take(len(data)).reduce(\n",
    "    initial_state={'class_0': 0, 'class_1': 0},\n",
    "    reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "fractions = counts/counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca399ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data to optimize learning time\n",
    "# from 0-255 (RGB) to 0-1\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "\n",
    "# used to get batches of our data\n",
    "batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels of a batch, 1 representing dirty, 0 clean\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ac846",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7) # To train the model\n",
    "val_size = int(len(data)*.2) # To finetune the model\n",
    "test_size = int(len(data)*.1) # To evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.skip(val_size + test_size).take(train_size)\n",
    "val = data.take(val_size)\n",
    "test = data.skip(val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25266e32",
   "metadata": {},
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80069dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(16, (3,3), 1, activation=\"leaky_relu\", input_shape=(256,256, 3)),\n",
    "        MaxPooling2D(), # Takes maximum value out of an area (default is (2,2))\n",
    "        # SpatialDropout2D(0.2),\n",
    "        # BatchNormalization(),\n",
    "        \n",
    "        Flatten(), # Condensing into a single dimension\n",
    "        \n",
    "        Dense(128, activation=\"leaky_relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59424fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74192a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f51f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=26, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95720351",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f6b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
