{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece21661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import imghdr\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, SpatialDropout2D, GlobalAveragePooling2D\n",
    "from keras.applications import MobileNetV2, EfficientNetV2B0 # pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d64a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'Detect_solar_dust'\n",
    "\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "# check all images are openable\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Failed to load image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Add random seed of training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore params\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for images, labels_batch in data:\n",
    "  labels.extend(labels_batch.numpy())\n",
    "\n",
    "plt.hist(labels)\n",
    "plt.xlabel('Class Name')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of image classes')\n",
    "\n",
    "# Set the x-axis tick labels to the class names\n",
    "plt.xticks(ticks=range(len(data.class_names)), labels=data.class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca399ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data to optimize learning time\n",
    "# from 0-255 (RGB) to 0-1\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "\n",
    "# used to get batches of our data\n",
    "batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels of a batch, 1 representing dirty, 0 clean\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ac846",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7) # To train the model\n",
    "val_size = int(len(data)*.2) # To finetune the model\n",
    "test_size = int(len(data)*.1) # To evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.skip(val_size + test_size).take(train_size)\n",
    "val = data.take(val_size)\n",
    "test = data.skip(val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25266e32",
   "metadata": {},
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(16, (3,3), 1, activation=\"leaky_relu\", input_shape=(224,224, 3)),\n",
    "        MaxPooling2D(), # Takes maximum value out of an area (default is (2,2))\n",
    "        # SpatialDropout2D(0.2),\n",
    "        # BatchNormalization(),\n",
    "        \n",
    "        Flatten(), # Condensing into a single dimension\n",
    "        \n",
    "        Dense(128, activation=\"leaky_relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9786333",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.append(('CNN', model.fit(train, epochs=26, validation_data=val))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80069dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning using a pre-trained MobileNetV2 network\n",
    "mobilenet_pretrained_model = Sequential([\n",
    "    # base\n",
    "    MobileNetV2(input_shape=(224, 224, 3),include_top=False, weights='imagenet'),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid'),   \n",
    "])\n",
    "# Weights are used from imagenet, don't re-train\n",
    "mobilenet_pretrained_model.layers[0].trainable= False\n",
    "\n",
    "# show model summary\n",
    "mobilenet_pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_pretrained_model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59424fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f51f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.append(('Pretrained MobileNet', mobilenet_pretrained_model.fit(train, epochs=17, validation_data=val))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c428901",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_elements = list(hist[0][1].history.keys())\n",
    "hist_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hist_elements:\n",
    "    print(i)\n",
    "    for j in hist:\n",
    "        plt.plot(range(len(j[1].history[i])), j[1].history[i], label=j[0])\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = mobilenet_pretrained_model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "\n",
    "print(pre.result(), re.result(), acc.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
